\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{tabularx,booktabs}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Chronic Kidney Disease Prediction from Machine Learning Classification \\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
}

\author{\IEEEauthorblockN{ Imesh Udara Ekanayake}
\IEEEauthorblockA{\textit{dept. Computer Engineering} \\
\textit{University of Peradeniya}\\
Peradeniya, Sri Lanka \\
imeshuek@eng.pdn.ac.lk}
\and
\IEEEauthorblockN{ Dr Damayanthi Herath}
\IEEEauthorblockA{\textit{dept. Computer Engineering} \\
\textit{University of Peradeniya}\\
Peradeniya, Sri Lanka \\
damayanthiherath@eng.pdn.ac.lk}
}

\maketitle

\begin{abstract}
Chronic Kidney Disease (CKD) or chronic renal disease has become a major issue with a steady growing rate.  A person can only survive without kidneys for average time of 18 days\cite{b0},which makes a huge demand for kidney transplant and Dialysis, by using machine learning classification algorithms with seven attributes it makes possible to identify and predict CKD with a perfect accuracy in early stages. 11 machine learning methods were evaluate and selected 5 algorithms with the highest accuracy and based on the distribution and bias of the feature importance of trained models, the Extra tree classifier and Random forest classifier as been selected. 
\end{abstract}

\begin{IEEEkeywords}
Chronic Kidney Disease, chronic renal disease, CKD, Machine Learning, Classification Algorithm,  Extra tree classifier, Random forest classifier
\end{IEEEkeywords}

\section{Introduction}
The kidneys are two bean-shaped organs, each about the size of a fist\cite{b1}. They are located just below the rib cage, one on each side of the spine. Every day, the kidneys filter about 120 to 150 quarts of blood to produce about 1 to 2 quarts of urine. the function of the kidneys is to remove waste products and excess fluid from the body through the urine. The production of urine involves highly complex steps of excretion and re-absorption. This process is necessary to maintain a stable balance of body chemicals. The critical regulation of the body's salt, potassium and acid content is performed by the kidneys and produce hormones that affect the function of other organs. For example, a hormone produced by the kidneys stimulates red blood cell production, regulate blood pressure and control calcium metabolism etc.

Chronic kidney disease (CKD) is a major issue worldwide which is a condition characterized by a gradual loss of kidney function over time, 14\% of the world population suffer from CKD. Over 2 million people worldwide currently receive treatment with dialysis or a kidney transplant to stay alive, yet this number may only represent 10\% of people who actually  need treatment to live. Chronic kidney disease, causes more deaths than breast cancer or prostate cancer and It is the under-recognized public health crisis. 

The stages of CKD are mainly based in the measured or estimated Glomerular Filtration Rate (eGFR) whityich is based on Creatinine level, Gender, Race and Age. There are Five stages, kidney functionality if normal in stage 1 and minimally reduced in stage 2, but the majority of cases are stage 3. 

\begin{figure}[h!]
\centerline{\includegraphics[width=8cm]{heat_map-Patient.jpg}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}

Machining Learning grabs a major part of artificial intelligent when it comes to do predictions from previous data using classification and regression methods. Moreover, if there are instances with missing attributes, based on the randomness of the way they missed, filling method should be properly determined.

In Addition, the UCI data-set\cite{b4} has only 400 instances with 25 attributes, which clearly indicates two possibilities, either the data set has redundant (highly co-related)  features or the data set is not representing all possibilities, which leads to feature engineering. Statistical understanding and the background of the problem most of the time goes along but sometimes bias attributes makes more seance with the actual effect from it for the problem.  

\section{Literature Review}
Since this rich data set is released, many number of researches have predicted CKD with different machine learning and data mining  techniques. 

A. J. Hussain and the team has obtained an accuracy of 0.995 of predicting CKD in early stages by multi-layer perception  and prepossessed data set with neural networks to fill the missing values, then discard the outlers and selected the optimal seven attributes with statistical analysis and discarded the attributes which has a higher inter co-relation by principal component analysis.\cite{b10}In this method the missing value filling algorithm made a significant impact on the accuracy of the trained models but because of using Neural Network for 20 attributes only with 260 fully completed data instances it slightly reduced the missing value prediction accuracy. Discarding attributes which has more than 20\% missing values made a huge effect on accuracy of replaced missing values and the categorization of attributes according to result obtaining substance such as blood, urine or other made it clear to select attributes for the training model from each category.

when consider the five stages of CKD, an Egypt research team has predicted each stage with the highest accuracy for a stage with 0.997 and overall accuracy of 0.967 while discarding instances with missing values by using probabilistic neural networks and calculating the eGFR using the above data set with additional data about gender and race.\cite{b6} The reason to reduce the accuracy in this model is using constants to replace missing values which clearly shows in table-2 that the randomness of missing data points are perfect according to Little's MCAR algorithm\cite{b13}. In the feature importance of the algorithm the importance is bias to wards serum creatinine, but in early stages of CKD this can stay at regular values and all other features combine importance does not exceed the importance of creatinine. The lack of medical perspective about the problem leads to question the reliability of the trained models when predicting the new instances outside the data set.

In 2017 a team of researchers as used 14 attributes to predict the CKD  and achieved 0.991 accuracy with Multi class Decision Forest.\cite{b11}Moreover, they have discarded the instances with missing values and  trained a neural network and a logistic regression model which gave 0.975 and 0.960 of overall accuracy. The attributes they have selected varies with co relation to the class from 0.2 to 0.8, when look at the attributes from medical perspective hypertension can cause CKD as well as CKD causes hypertension and specific gravity has 0.73 co-relation to the class, discarding these type of attributes keep the accuracy below perfect. 

In 2015 Lambodar J. and Narendra Ku. K. has created eight machine learning models using WEKA data mining tool.\cite{b11} The highest ROC(Receiver Operating Characteristic) and accuracies were given by Naive Bayes, Multi-layer Perception and J48 algorithms as ROC of 1 and accuracy of 0.950, 0.9975 and 0.99. 





\section{Methodology}
The flowchart in the figure 2 shows the way data has processed from raw data to prediction model selection 

\begin{figure}[h!]
\centerline{\includegraphics[width=10cm]{method.png}}
\caption{Data Processing Method.}
\label{fig}
\end{figure}




\section{Prepossessing analysis of the Data set}
The attributes with more than 20\% missing values ("red blood cells", "sodium", "potassium", "white blood cell count”, "red blood cell count”) has been discarded because of the error that will occurs when filling them.

\begin{table}[h!]
\centering
 \caption{CIFAR-10 Confusion Matrix}
\label{my-label}
 \begin{tabular}{c c} 
 \toprule
 ATTRIBUTE  & MISSING PERCENTAGE  \\ [0.5ex] 
 \midrule
CLASS   & 0.00 \%\\
APPETITE &	0.25 \%\\
PEDAL EDEMA &	0.25 \%\\
ANEMIA &	0.25 \%\\
HYPERTENSION &	0.50 \%\\
DIABETES MELLITUS & 	0.50 \%\\
CORONARY ARTERY DISEASE 	& 0.50 \%\\
PUS CELL CLUMPS &	1.00 \%\\
BACTERIA &	1.00 \%\\
AGE &	2.2 5 \%\\
BLOOD PRESSURE & 	3.00 \%\\
SERUM CREATININE &	4.25 \%\\
BLOOD UREA & 	4.75 \%\\
BLOOD GLUCOSE RANDOM 	& 11.00 \%\\
ALBUMIN  &	11.50 \%\\
SPECIFIC GRAVITY &	11.75 \%\\
SUGAR &	12.25 \%\\
HEMOGLOBIN &	13.00 \%\\
PUS CELL &	16.25 \%\\
PACKED CELL VOLUME & 	17.50 \%\\
\color{red}SODIUM &	\color{red}21.75 \%\\
\color{red}POTASSIUM &	\color{red}22.00 \%\\
\color{red}WHITE BLOOD CELL COUNT	& \color{red}26.25 \%\\
\color{red}RED BLOOD CELL COUNT 	& \color{red}32.50 \%\\
\color{red}RED BLOOD CELLS &	\color{red}38.00  \%\\
 [0.5ex] 
 \toprule
 \end{tabular}
\end{table}
In the pre-processing the incomplete data handling grabs a major portion of it, depending on the way the missing data are distributed it should be treated in different ways with different assumption about them, one of them is missing completely at random, to validate this assumption the Little’s MCAR test has been done.
If missing data mechanism depends on the unobserved data, data are missing not at random so chi-square test of MCAR for multivariate quantitative data proposed by Little (1988), which tests whether there exists significant difference between the 1 means of different missing-value patterns.

\begin{table}[h!]
\centering
 \caption{CIFAR-10 Confusion Matrix}
\label{my-label}
 \begin{tabular}{c c} 
 \toprule
 Name  & Value  \\ [0.5ex] 
 \midrule
Chi.Square   & 3160.494 \\
degree of freedom &	2164 \\
P.value &	0 \\
Missing patterns &	105 \\
 [0.5ex] 
 \toprule
 \end{tabular}
\end{table}

From Little's MCAR output in Table 2 it clearly shows from the “P” value, since its zero the data has missed completely random. Therefore, substituting missing values with a constant will rapidly drop the accuracy and it will bias the prediction since more CKD positive instances are there. Which led to fill missing values with a more algorithmic approach from K Nearest Neighbor Algorithm. 
When applying the algorithm, since all patients are different from each other, which led to use number of estimators as same the number of complete instances, which gave the minimum mean and standard deviation change, since the missing values are missed completely randomly.

\begin{figure}[h!]
\centerline{\includegraphics[width=8cm]{comex.png}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}

When consider the absolute values of the above matrix of the class attribute. It clearly shows “Hemoglobin”, “Specific Gravity”, “Albumin”, “Hypertension” and “Diabetes mellitus” have the highest correlations more than 0.5. Then the secondary attributes “Pus cell”, “Blood glucose Random”, “appetite”, “Blood Urea”, “pedal edema”, “Sugar”, “Anemia” and “Serum Creatinine” are the attributes which has correlation more than 0.3.

%=============================================================================
\begin{table*}
 \caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\begin{tabularx}{\textwidth}{@{}l*{12}{C}c@{}}
\toprule
\% & Hb & 
 \begin{tabular}[c]{@{}l@{}}Specific \\Gravity\end{tabular}& 
 Albumin & 
 Hypertension & 
 \begin{tabular}[c]{@{}l@{}}Diabetes\\Mellitus\end{tabular}& 
 pus cell & 
 \begin{tabular}[c]{@{}l@{}}Blood\\Glucose\\Random\end{tabular}& 
 Appetite & BU &
 \begin{tabular}[c]{@{}l@{}}Pedal \\ Edema\end{tabular} & 
 sugar & Anemia &
 \begin{tabular}[c]{@{}l@{}}Serum\\Creatinine\end{tabular}\\
\midrule
count & 13.00 & 11.75 & 11.50  & 0.50  & 0.50  & 16.25 & 11.00 & 0.25  & 4.75  & 0.25  & 12.25 & 0.25  & 4.25  \\
            mean  & 0.66  & 0.01 & -1.39  & -0.34 & -0.36 & -2.22 & -0.14 & 0.04  & -0.22 & -0.10 & -4.53 & -0.15 & -0.43 \\
            std   & -6.32 & -6.15 & -5.95  & -0.19 & -0.19 & -8.94 & -5.86 & -0.12 & -2.43 & -0.12 & -6.30 & -0.12 & -2.16 \\
            min   & 0.00  & 0.00  & 0.00   & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  \\
            25  & 5.29  & 0.49  & 0.00   & 0.00  & 0.00  & 0.00  & 1.98  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  \\
            50  & 2.62  & -0.12 & 100 & 0.00  & 0.00  & 0.00  & 3.97  & 0.00  & 4.55  & 0.00  & 0.00  & 0.00  & 7.14  \\
            75  & -2.56 & 0.00  & 0.00   & 0.00  & 0.00  & 100   & -2.56 & 0.00  & -3.00 & 0.00  & 100   & 0.00  & 0.89  \\
            max   & 0.00 & 0.00  & 0.00   & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00  & 0.00 \\
\bottomrule
\end{tabularx}
\end{table*}

%=============================================================================

Specific Gravity and Albumin has only 5 sets of values in each, when plot the values in a 2D graph it clearly shows a cluster in that with CKD negative instances.
A test for protein in the urine. Estimates the amount of a albumin that is in your urine. An excess amount of protein in your urine may mean your kidney's filtering units have been damaged by disease or due to fever or heavy exercise, test should be confirmed over several weeks.
\begin{figure}[h!]
\centerline{\includegraphics[width=8cm]{albVSsg.png}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}

 
 There are a number of ways to increase hemoglobin levels. In general, low hemoglobin levels that need to be increased are caused by three circumstances: decreased red blood cell production, increased red blood cell destruction and by blood loss. Healthy kidneys produce a hormone called erythro poietin (EPO). A hormone is a chemical produced by the body and released into the blood to help trigger or regulate particular body functions. EPO prompts the bone marrow to make red blood cells, which then carry oxygen throughout the body. When kidneys are diseased or damaged, they do not make enough EPO. As a result, the bone marrow makes fewer red blood cells, causing anemia but before it causes anemia (which happens after less than 50% of one kidney is properly functions),  the hemoglobin levels changes slightly.
From the Hemoglobin vs Serum Creatinine 2D plot clearly shows 2 different clusters of CKD positive and Negative.

\begin{figure}[h!]
\centerline{\includegraphics[width=8cm]{HemoVsSeCreat.png}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}


Serum Creatinine also known as Creat, Blood Creatinine, Creatinine. Creatinine is a waste product produced by muscles from the breakdown of a compound called creatine. Creatinine is removed from the body by the kidneys, which filter almost all of it from the blood and release it into the urine. This test measures the amount of creatinine in the blood. Creatine is part of the cycle that produces energy needed to contract muscles. Both creatine and creatinine are produced by the body at a relatively constant rate. Apart from issues directly related to kidney, a high-protein diet, congestive heart failure, complications of diabetes and dehydration can also increase the level of creatinine in the blood. The normal serum creatinine range is 0.6–1.1 mg/dL in women and 0.7–1.3 mg/dL in men.
The two main causes of chronic kidney disease are diabetes and high blood pressure, which are responsible for up to two-thirds of the cases. Diabetes happens when the blood sugar is too high, causing damage to many organs in the body, including the kidneys and heart, as well as blood vessels, nerves and eyes. High blood pressure, or hypertension, occurs when the pressure of your blood against the walls of your blood vessels increases. If uncontrolled, or poorly controlled, high blood pressure can be a leading cause of heart attacks, strokes and chronic kidney disease. Also, chronic kidney disease can cause high blood pressure.

\begin{figure}[h!]
\centerline{\includegraphics[width=6cm]{dmVsHyp.png}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}
 
The next important concern is how easy and feasible it is to obtain the attribute. The following tests mention in the table have to be done to obtain the attributes along with.

\begin{table}[!h]
\centering
\caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\begin{tabular}{ll}
\toprule
Attribute & Test/way to obtain \\
\midrule
blood urea & BLOOD UREA \\
age & \begin{tabular}[c]{@{}l@{}}Doctor's   Inspection\end{tabular} \\
blood pressure & Doctor's Inspection \\
hypertension & \begin{tabular}[c]{@{}l@{}}Doctor's Inspection\end{tabular} \\
coronary artery disease & Doctor's Inspection \\
appetite & \begin{tabular}[c]{@{}l@{}}Doctor's Inspection\end{tabular} \\
pedal edema & Doctor's Inspection \\
hemoglobin & FBC \\
white blood cell count & FBC \\
red blood cell count & FBC \\
anemia & FBC \\
packed cell volume & FBC \\
diabetes mellitus & FBS \\
blood glucose random & RBS \\
serum creatinine & SERUM CREATININE \\
sodium & \begin{tabular}[c]{@{}l@{}}SERUM   ELECTROIDES\end{tabular} \\
potassium & SERUM ELECTROIDES \\
pus cell clumps & UFR \\
specific gravity & UFR \\
albumin & UFR \\
sugar & UFR \\
red blood cells & UFR \\
pus cell & UFR \\
bacteria & UFR\\
\toprule
\end{tabular}
\end{table}
 

 
 
 
When consider Parameters like “appetite”, 

 \begin{figure}[!h]
\centerline{\includegraphics[width=8cm]{appetite.png}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}

 The Distribution of the parameter with the class is bias towards “good appetite” (CKD is not the only reason to have a poor appetite), which will mislead the predictions when apply the training model to a new scenario.   
Therefore, the correlation to the classification and to other attributes, distribution and the bias of the variable towards one extent and the medical perspective of the attribute have been considered to select "hemoglobin", "specific gravity", "albumin", "hypertension", "diabetes mellitus", "blood glucose random" and “serum creatinine” as the optimal subset of parameters to do the prediction.


 
 
 \section*{Training the system}
 
 Initially 11 different classification models were training a Logistic Regression, KNN Regression, SVC with a Linear kernel, SVC with RBF kernel, Gaussian NB, a Decision Tree Classifier, Random Forest Classifier, XGB Classifier, Extra Trees Classifier, an Ada Boost Classifier and a Classical Neural Network. Then the dataset has been divided into 3 parts as 70\% Training data, 15\% cross validation data and 15\% test data randomly.
Thereafter, the models were optimized for the Training dataset and has done the initial accuracy and error test from the cross-validation dataset and tested. From the above 11 algorithms, 6 algorithms out perform in Training accuracy, Testing accuracy and in cross validation accuracy. Which are the Decision Tree Classifier, Random Forest Classifier, XGB Classifier, Extra Trees Classifier, Ada Boost Classifier and Classical Neural Network.

\begin{table}[!h]
 \caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\centering
\begin{tabular}{llll}
\toprule
Algorithm & \begin{tabular}[c]{@{}l@{}}Training \\ Accuracy\end{tabular} & \begin{tabular}[c]{@{}l@{}}cv \\ Accuracy\end{tabular} & \begin{tabular}[c]{@{}l@{}}Testing \\ Accuracy\end{tabular} \\
\midrule
Logistic Regression & 96.07\% & 96.66\% & 95.00\% \\
KNN & 97.85\% & 98.33\% & 98.33\% \\
SVC Linear & 97.14\% & 96.66\% & 96.66\% \\
SVC RBF & 94.64\% & 95.00\% & 95.00\% \\
Gaussian NB & 95.35\% & 95.00\% & 93.33\% \\
Decision Tree Classifier & 100\% & 100\% & 100\% \\
Random Forest Classifier & 100\% & 100\% & 100\% \\
XGB Classifier & 99.28\% & 100\% & 100\% \\
Extra Trees Classifier & 100\% & 100\% & 100\% \\
Ada Boost Classifier & 100\% & 100\% & 100\% \\
Classical   Neural Network & 97.81\% & 97.50\% & 97.50\%\\
\toprule
\end{tabular}
\end{table}

\begin{table}[!h]
\caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\centering
\begin{tabular}{llll}
\toprule
Algorithm & Precision & Recall & F1-Score \\
\midrule
Logistic Regression & 1.000 & 0.925 & 0.961 \\
KNN & 1.000 & 0.975 & 0.987 \\
SVC Linear & 1.000 & 0.950 & 0.974 \\
SVC RBF & 1.000 & 0.925 & 0.961 \\
Gaussian NB & 0.973 & 0.925 & 0.948 \\
Decision Tree Classifier & 1.000 & 1.000 & 1.000 \\
Random Forest Classifier & 1.000 & 1.000 & 1.000 \\
XGB Classifier & 1.000 & 1.000 & 1.000 \\
Extra Trees Classifier & 1.000 & 1.000 & 1.000 \\
Ada Boost Classifier & 1.000 & 1.000 & 1.000 \\
Classical Neural Network & 0.962 & 1.000 & 0.981\\
\toprule
\end{tabular}
\end{table}

%=============================================================================
\begin{table*}
\caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\begin{tabularx}{\textwidth}{@{}l*{10}{C}c@{}}
\toprule
Attribute & Decision Tree Classifier & Random Forest Classifier & XGB Classifier & Extra Trees Classifier & Ada Boost Classifier \\
\midrule
Hemoglobin & 0.580 & 0.246 & 0.252 & 0.174 & 0.330 \\
Specific Gravity & 0.265 & 0.275 & 0.135 & 0.242 & 0.320 \\
Serum Creatinine & 0.031 & 0.160 & 0.500 & 0.057 & 0.000 \\
Albumin & 0.103 & 0.196 & 0.089 & 0.158 & 0.140 \\
Hypertension & 0.000 & 0.051 & 0.000 & 0.192 & 0.130 \\
Diabetes Mellitus & 0.000 & 0.026 & 0.000 & 0.130 & 0.080 \\
Blood Glucose Random & 0.022 & 0.046 & 0.024 & 0.048 & 0.000\\
\bottomrule
\end{tabularx}
\end{table*}
%============================================================================
%=============================================================================
\begin{table*}[]
 \caption{CIFAR-10 Confusion Matrix}
\label{my-label}
\centering
\begin{tabularx}{\textwidth}{@{}l*{10}{C}c@{}}
\toprule
Attribute & Decision Tree Classifier & Random Forest Classifier & XGB Classifier & Extra Trees Classifier & Ada Boost Classifier \\
\midrule
Standard Deviation & 0.214295746 & 0.102219419 & 0.181369263 & 0.070684746 & 0.136224604\\
\bottomrule
\end{tabularx}
\end{table*}
%=============================================================================
 

Based on the above results the, the algorithms which gave perfect accuracy in all 3 data sets were selected. which are Decision Tree Classifier,	Random Forest Classifier,	XGB Classifier,	Extra Trees Classifier and	Ada Boost Classifier.

Moreover, even though models gave 100\% its important to check which attributed make the highest impact on each model to take the decision.





After identifying the importance of selected features for each prediction algorithm the standard deviation of the feature importance of each algorithm has calculated, which explicit the algorithm’s bias towards different features. 



When consider the standard deviations and above graph it’s clear that Extra Trees Classifier has the lowest bias towards features and next the Random Forest Classifier. Decision Tree Classifier has the highest bias of all. 

\begin{figure}[h!]
\centerline{\includegraphics[width=9cm]{importance.jpg}}
\caption{Feat map of the severity.}
\label{fig}
\end{figure}



 \section*{Conclusion }
 In conclusion the Chronic kidney disease is a life threatening issue that affects almost 14\% of the world population and predicting it with a 100\% overall accuracy makes it possible for people for get to know it in the early stages to get treated with a minimum cost and minimum risk. 
Proper feature engineering helps to reduce number of features need for the prediction algorithm and practically it reduces the number of medical tests to take. Filling missing values based on the distribution of them along with the collocation of other attributes, other than replace with a constant, directly leads to higher accuracies in prediction models.
Finally, the Extra Trees Classifier and the Random Forest Classifier are the better algorithms to do the predictions for CKD since those has 100\% overall accuracy and minimal bias towards specific attributes compare to other models. 





\begin{thebibliography}{00}

\bibitem{b0} Murtagh, F., Addington-Hall, J., Edmonds, P., Donohoe, P., Carey, I., Jenkins, K. and Higginson, I. (2010). Symptoms in the Month Before Death for Stage 5 Chronic Kidney Disease Patients Managed Without Dialysis. Journal of Pain and Symptom Management, 40(3), pp.342-352.

\bibitem{b1} Your Kidneys & How They Work | NIDDK. [online] National Institute of Diabetes and Digestive and Kidney Diseases. Available at: https://www.niddk.nih.gov/health-information/kidney-disease/kidneys-how-they-work [Accessed 4 Feb. 2020].

\bibitem{b2}  National Institute of Diabetes and Digestive and Kidney Diseases. [online] Available at:https://www.niddk.nih.gov/health-information/kidney-disease/kidneys-how-they-work [Accessed 4 Feb. 2020].

\bibitem{b3} National Kidney Foundation. (2020). How Your Kidneys Work. [online] Available at: https://www.kidney.org/kidneydisease/howkidneyswrk [Accessed 4 Feb. 2020].


\bibitem{b4}Archive.ics.uci.edu. (2020). UCI Machine Learning Repository: Chronic\_Kidney\_Disease Data Set. [online] Available at: https://archive.ics.uci.edu/ml/datasets/Chronic\_Kidney\_Disease [Accessed 4 Feb. 2020]

\bibitem{b5} National Kidney Foundation. (2020). Global Facts: About Kidney Disease. [online] Available at : https://www.kidney.org/kidneydisease/global-facts-about-kidney-disease[Accessed 4 Feb. 2020].

\bibitem{b6}Rady, E. and Anwar, A. (2019). Prediction of kidney disease stages using data mining algorithms. Informatics in Medicine Unlocked, 15, p.100178.

\bibitem{b7} National Kidney Foundation. (2020). Estimated Glomerular Filtration Rate (eGFR). [online] Available at: https://www.kidney.org/atoz/content/gfr [Accessed 4 Feb. 2020].

\bibitem{b8} Labtestsonline.org. (2020). Creatinine | Lab Tests Online. [online] Available at: https://labtestsonline.org/tests/creatinine [Accessed 4 Feb. 2020].

\bibitem{b9} National Kidney Foundation. (2020). Facts About Chronic Kidney Disease. [online] Available at: https://www.kidney.org/atoz/content/about-chronic-kidney-disease [Accessed 4 Feb. 2020].

\bibitem{b10} A. J. Aljaaf, D. Al-Jumeily, H. M. Haglan, M. Alloghani, T. Baker,
A. J. Hussain, and J. Mustafina, ‘‘Early prediction of chronic kidney
disease using machine learning supported by predictive analytics,’’ in
Proc. IEEE Congr. Evol. Comput. (CEC), Jul. 2018, pp. 1–9

\bibitem{b11}W. H. S. Gunarathne, K. D. Perera, K. A. D. C. Kahandawaarachchi, "Performance Evaluation on Machine Learning Classification Techniques for Disease Classification and Forecasting through Data Analytics for chronic Kidney Disease (CKD)", 2017 IEEE 17th International Conference on Bioinformatics and Bioengineering (BIBE), pp. 291-296, 2017.

\bibitem{b12}S, V. and S, D. (2015). Data Mining Classification Algorithms for Kidney Disease Prediction. International Journal on Cybernetics & Informatics, 4(4), pp.13-25.

\bibitem{b13}Li, C. (2013). Little's Test of Missing Completely at Random. The Stata Journal: Promoting communications on statistics and Stata, 13(4), pp.795-809.

\end{thebibliography}


\end{document}
